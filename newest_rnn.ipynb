{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1f9c7b896ad9b3f9ee75e3451b128b949bdc39c3"
   },
   "source": [
    "## Using self-trained embeddings from train_active on the description\n",
    "\n",
    "This kernel shows how to use the Word2Vec model created in [this kernel](https://www.kaggle.com/christofhenkel/using-train-active-for-training-word-embeddings) on the description. To compare the performance with [the pre-trained embedding model](https://www.kaggle.com/christofhenkel/fasttext-starter-description-only) we use exactly the same model structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "cd154f8d-298b-4c43-b244-abe4a3b4b72e",
    "_uuid": "cbad1e4cb69e82f118cf32da7880edbc90098a31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import word2vec\n",
    "from keras.preprocessing import text, sequence\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.layers import Input, SpatialDropout1D,Dropout, GlobalAveragePooling1D, CuDNNGRU, Bidirectional, Dense, Embedding\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "EMBEDDING = 'avito.vec'\n",
    "TRAIN_CSV = 'train.csv'\n",
    "TEST_CSV = 'test.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train...\n",
      "loading test\n",
      "concat dfs\n"
     ]
    }
   ],
   "source": [
    "text_cols = ['param_1','param_2','param_3','title','description']\n",
    "print('loading train...')\n",
    "train = pd.read_csv('train.csv', index_col = 'item_id', usecols = text_cols + ['item_id','image_top_1','deal_probability', 'param_1', 'param_2', 'param_3', \n",
    "    'city', 'region', 'category_name', 'parent_category_name', 'user_type'])\n",
    "train_indices = train.index\n",
    "print('loading test')\n",
    "test = pd.read_csv('test.csv', index_col = 'item_id', usecols = text_cols + ['item_id','image_top_1', 'param_1', 'param_2', 'param_3', \n",
    "    'city', 'region', 'category_name', 'parent_category_name', 'user_type'])\n",
    "test_indices = test.index\n",
    "print('concat dfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt in text_cols:\n",
    "    train[txt]  = train[txt].astype(str)\n",
    "    test[txt]  = test[txt].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train[text_cols].apply(lambda x: ' '.join(x), axis=1)\n",
    "train.drop(text_cols,axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'] = test[text_cols].apply(lambda x: ' '.join(x), axis=1)\n",
    "test.drop(text_cols,axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "1c996a20-0524-4689-b62a-245f7940a67a",
    "_uuid": "965cc2439216eda704f32e677f947a03977ad43d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting tokenizer...done.\n"
     ]
    }
   ],
   "source": [
    "max_features = 100000\n",
    "maxlen = 200\n",
    "embed_size = 300\n",
    "labels = train[['deal_probability']].copy()\n",
    "train = train[['text']].copy()\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "\n",
    "print('fitting tokenizer...',end='')\n",
    "tokenizer.fit_on_texts(list(train['text'].fillna('NA').values))\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "0cde366b-2bfc-4217-ab3d-2c265b3a1319",
    "_uuid": "1a401fc2a67f34413fbf8f7bc26725a3558056c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec.load(EMBEDDING)\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    try:\n",
    "        embedding_vector = model[word]\n",
    "    except KeyError:\n",
    "        embedding_vector = None\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = 'wiki.ru.vec'\n",
    "embeddings_index = {}\n",
    "with open(EMBEDDING_FILE, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float16')\n",
    "        embeddings_index[word] = coefs\n",
    "word_index = tokenizer.word_index\n",
    "#prepare embedding matrix\n",
    "num_words = min(max_features, len(word_index) + 1)\n",
    "embedding_matrix_image = np.zeros((num_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix_image[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_train = pd.read_csv('translated_train.csv')\n",
    "translated_test = pd.read_csv('translated_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>activation_date</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>deal_probability</th>\n",
       "      <th>en_desc</th>\n",
       "      <th>en_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>e00f8ff2eaf9</td>\n",
       "      <td>Свердловская область</td>\n",
       "      <td>Екатеринбург</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Кокоби(кокон для сна)</td>\n",
       "      <td>Кокон для сна малыша,пользовались меньше месяц...</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>Private</td>\n",
       "      <td>d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>0.12789</td>\n",
       "      <td>Cocoon for sleeping baby, enjoyed less than a ...</td>\n",
       "      <td>Kokobi (cocoon for sleep)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>39aeb48f0017</td>\n",
       "      <td>Самарская область</td>\n",
       "      <td>Самара</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>Другое</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Стойка для Одежды</td>\n",
       "      <td>Стойка для одежды, под вешалки. С бутика.</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>Private</td>\n",
       "      <td>79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...</td>\n",
       "      <td>692.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>Rack for clothes, under hangers. From the bout...</td>\n",
       "      <td>Rack for Clothes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>91e2f88dd6e3</td>\n",
       "      <td>Ростовская область</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "      <td>Бытовая электроника</td>\n",
       "      <td>Аудио и видео</td>\n",
       "      <td>Видео, DVD и Blu-ray плееры</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips bluray</td>\n",
       "      <td>В хорошем состоянии, домашний кинотеатр с blu ...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>Private</td>\n",
       "      <td>b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>0.43177</td>\n",
       "      <td>In good condition, home theater with blu ray, ...</td>\n",
       "      <td>Philips bluray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>bf5cccea572d</td>\n",
       "      <td>Татарстан</td>\n",
       "      <td>Набережные Челны</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Автокресло</td>\n",
       "      <td>Продам кресло от0-25кг</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>286</td>\n",
       "      <td>2017-03-25</td>\n",
       "      <td>Company</td>\n",
       "      <td>e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...</td>\n",
       "      <td>796.0</td>\n",
       "      <td>0.80323</td>\n",
       "      <td>Selling an armchair from 0-25kg</td>\n",
       "      <td>Car seat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>ef50846afc0b</td>\n",
       "      <td>Волгоградская область</td>\n",
       "      <td>Волгоград</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили</td>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>2110</td>\n",
       "      <td>ВАЗ 2110, 2003</td>\n",
       "      <td>Все вопросы по телефону.</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>Private</td>\n",
       "      <td>54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>0.20797</td>\n",
       "      <td>All questions on the phone.</td>\n",
       "      <td>VAZ 2110, 2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id       user_id                 region              city  \\\n",
       "0  b912c3c6a6ad  e00f8ff2eaf9   Свердловская область      Екатеринбург   \n",
       "1  2dac0150717d  39aeb48f0017      Самарская область            Самара   \n",
       "2  ba83aefab5dc  91e2f88dd6e3     Ростовская область    Ростов-на-Дону   \n",
       "3  02996f1dd2ea  bf5cccea572d              Татарстан  Набережные Челны   \n",
       "4  7c90be56d2ab  ef50846afc0b  Волгоградская область         Волгоград   \n",
       "\n",
       "  parent_category_name               category_name  \\\n",
       "0          Личные вещи  Товары для детей и игрушки   \n",
       "1      Для дома и дачи           Мебель и интерьер   \n",
       "2  Бытовая электроника               Аудио и видео   \n",
       "3          Личные вещи  Товары для детей и игрушки   \n",
       "4            Транспорт                  Автомобили   \n",
       "\n",
       "                       param_1     param_2 param_3                  title  \\\n",
       "0    Постельные принадлежности         NaN     NaN  Кокоби(кокон для сна)   \n",
       "1                       Другое         NaN     NaN      Стойка для Одежды   \n",
       "2  Видео, DVD и Blu-ray плееры         NaN     NaN         Philips bluray   \n",
       "3         Автомобильные кресла         NaN     NaN             Автокресло   \n",
       "4                   С пробегом  ВАЗ (LADA)    2110         ВАЗ 2110, 2003   \n",
       "\n",
       "                                         description    price  \\\n",
       "0  Кокон для сна малыша,пользовались меньше месяц...    400.0   \n",
       "1          Стойка для одежды, под вешалки. С бутика.   3000.0   \n",
       "2  В хорошем состоянии, домашний кинотеатр с blu ...   4000.0   \n",
       "3                             Продам кресло от0-25кг   2200.0   \n",
       "4                           Все вопросы по телефону.  40000.0   \n",
       "\n",
       "   item_seq_number activation_date user_type  \\\n",
       "0                2      2017-03-28   Private   \n",
       "1               19      2017-03-26   Private   \n",
       "2                9      2017-03-20   Private   \n",
       "3              286      2017-03-25   Company   \n",
       "4                3      2017-03-16   Private   \n",
       "\n",
       "                                               image  image_top_1  \\\n",
       "0  d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...       1008.0   \n",
       "1  79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...        692.0   \n",
       "2  b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...       3032.0   \n",
       "3  e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...        796.0   \n",
       "4  54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...       2264.0   \n",
       "\n",
       "   deal_probability                                            en_desc  \\\n",
       "0           0.12789  Cocoon for sleeping baby, enjoyed less than a ...   \n",
       "1           0.00000  Rack for clothes, under hangers. From the bout...   \n",
       "2           0.43177  In good condition, home theater with blu ray, ...   \n",
       "3           0.80323                    Selling an armchair from 0-25kg   \n",
       "4           0.20797                        All questions on the phone.   \n",
       "\n",
       "                    en_title  \n",
       "0  Kokobi (cocoon for sleep)  \n",
       "1           Rack for Clothes  \n",
       "2             Philips bluray  \n",
       "3                   Car seat  \n",
       "4             VAZ 2110, 2003  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_train['text'] = translated_train['en_desc'] +' '+ translated_train['en_title']\n",
    "translated_test['text'] = translated_test['en_desc'] +' '+ translated_test['en_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    \"\"\"\n",
    "    Given a text, cleans and normalizes it. Feel free to add your own stuff.\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Replace ips\n",
    "    s = re.sub(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', ' _ip_ ', s)\n",
    "    # Isolate punctuation\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\-\\\\\\/\\,])', r' \\1 ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Replace numbers and symbols with language\n",
    "    s = s.replace('&', ' and ')\n",
    "    s = s.replace('@', ' at ')\n",
    "    s = s.replace('0', ' zero ')\n",
    "    s = s.replace('1', ' one ')\n",
    "    s = s.replace('2', ' two ')\n",
    "    s = s.replace('3', ' three ')\n",
    "    s = s.replace('4', ' four ')\n",
    "    s = s.replace('5', ' five ')\n",
    "    s = s.replace('6', ' six ')\n",
    "    s = s.replace('7', ' seven ')\n",
    "    s = s.replace('8', ' eight ')\n",
    "    s = s.replace('9', ' nine ')\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting tokenizer...done.\n"
     ]
    }
   ],
   "source": [
    "max_features = 100000\n",
    "maxlen = 200\n",
    "embed_size = 300\n",
    "translated_train = translated_train[['text']].copy()\n",
    "translated_test = translated_test[['text']].copy()\n",
    "\n",
    "\n",
    "tokenizer_en = text.Tokenizer(num_words=max_features)\n",
    "\n",
    "print('fitting tokenizer...',end='')\n",
    "tokenizer_en.fit_on_texts(list(translated_train['text'].fillna('unknown').values) + list(translated_test['text'].fillna('unknown').values))\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "EMBEDDING_FILE = 'glove.840B.300d.txt'\n",
    "embeddings_index = {}\n",
    "with open(EMBEDDING_FILE, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float16')\n",
    "        embeddings_index[word] = coefs\n",
    "word_index = tokenizer_en.word_index\n",
    "#prepare embedding matrix\n",
    "num_words = min(max_features, len(word_index) + 1)\n",
    "embedding_matrix_image_two = np.zeros((num_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix_image_two[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastText import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "#prepare embedding matrix\n",
    "num_words = min(max_features, len(word_index) + 1)\n",
    "embedding_matrix_image = np.zeros((num_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix_image[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model = load_model(EMBEDDING_FILE1)\n",
    "words_in_model = set(lang_model.get_words())\n",
    "words_seen = set()\n",
    "words_seen_in_model = set()\n",
    "word_index = tokenizer.word_index\n",
    "embedding_matrix_image_two = np.zeros((num_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    #nonchars.update(set(word).difference( chars))\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = lang_model.get_word_vector(word)[:embed_size]\n",
    "    words_seen.add(word)\n",
    "    if word in words_in_model:\n",
    "        words_seen_in_model.add(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix_image_two[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "padding...done.\n",
      "padding\n"
     ]
    }
   ],
   "source": [
    "X_eng_train = tokenizer_en.texts_to_sequences(translated_train['text'].values)\n",
    "print('done.')\n",
    "print('padding...',end='')\n",
    "X_eng_train = sequence.pad_sequences(X_eng_train, maxlen=maxlen)\n",
    "print('done.')\n",
    "X_eng_test = translated_test['text'].values\n",
    "X_eng_test = tokenizer_en.texts_to_sequences(X_eng_test)\n",
    "\n",
    "print('padding')\n",
    "X_eng_test = sequence.pad_sequences(X_eng_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "padding...done.\n"
     ]
    }
   ],
   "source": [
    "X_train = tokenizer.texts_to_sequences(train['text'].values)\n",
    "print('done.')\n",
    "print('padding...',end='')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "print('done.')\n",
    "\n",
    "#del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding\n"
     ]
    }
   ],
   "source": [
    "test = test[['text']].copy()\n",
    "X_test = test['text'].values\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "print('padding')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "\n",
    "gp = pd.read_csv('aggregated_features.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train = train.merge(gp, on='user_id', how='left')\n",
    "test = test.merge(gp, on='user_id', how='left')\n",
    "train['avg_days_up_user'] = np.log1p(train['avg_days_up_user'])\n",
    "train['avg_times_up_user'] = np.log1p(train['avg_times_up_user'])\n",
    "train['n_user_items'] = np.log1p(train['n_user_items'])\n",
    "test['avg_days_up_user'] = np.log1p(test['avg_days_up_user'])\n",
    "test['avg_times_up_user'] = np.log1p(test['avg_times_up_user'])\n",
    "test['n_user_items'] = np.log1p(test['n_user_items'])\n",
    "\n",
    "\n",
    "temp_all = pd.concat([train[['price','avg_days_up_user','avg_times_up_user','n_user_items']],\n",
    "                      test[['price','avg_days_up_user','avg_times_up_user','n_user_items']]])\n",
    "temp_all[\"price\"] = np.log(temp_all[\"price\"]+0.001)\n",
    "train[\"price\"] = np.log(train[\"price\"]+0.001)\n",
    "train[\"price\"].fillna(temp_all['price'].mean(),inplace=True)\n",
    "test[\"price\"] = np.log(test[\"price\"]+0.001)\n",
    "test[\"price\"].fillna(temp_all['price'].mean(),inplace=True)\n",
    "\n",
    "train[\"avg_days_up_user\"].fillna(temp_all['avg_days_up_user'].max(),inplace=True)\n",
    "train[\"avg_times_up_user\"].fillna(temp_all['avg_times_up_user'].max(),inplace=True)\n",
    "train[\"n_user_items\"].fillna(temp_all['n_user_items'].max(),inplace=True)\n",
    "test[\"avg_days_up_user\"].fillna(temp_all['avg_days_up_user'].max(),inplace=True)\n",
    "test[\"avg_times_up_user\"].fillna(temp_all['avg_times_up_user'].max(),inplace=True)\n",
    "test[\"n_user_items\"].fillna(temp_all['n_user_items'].max(),inplace=True)\n",
    "\n",
    "\n",
    "extra_feat = ['avg_days_up_user','avg_times_up_user','n_user_items']\n",
    "for ef in extra_feat:\n",
    "    train[ef].fillna(temp_all[ef].max(),inplace=True)\n",
    "    test[ef].fillna(temp_all[ef].max(),inplace=True)\n",
    "features = train[['price','avg_days_up_user','avg_times_up_user','n_user_items']]\n",
    "test_features = test[['price','avg_days_up_user','avg_times_up_user','n_user_items']]\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(np.vstack([features, test_features]))\n",
    "features = ss.transform(features)\n",
    "test_features = ss.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_top_train = pd.read_csv(\"train_image_top_1_features.csv\") \n",
    "image_top_test = pd.read_csv(\"test_image_top_1_features.csv\") \n",
    "train['image_top_1'] = image_top_train['image_top_1']\n",
    "test['image_top_1'] = image_top_test['image_top_1']\n",
    "\n",
    "\n",
    "train['category_name'] = train['category_name'].astype('category')\n",
    "train['parent_category_name'] = train['parent_category_name'].astype('category')\n",
    "train['region'] = train['region'].astype('category')\n",
    "train['city'] = train['city'].astype('category')\n",
    "train['image_top_1'] = train['image_top_1'].fillna('missing')\n",
    "\n",
    "test['category_name'] = test['category_name'].astype('category')\n",
    "test['parent_category_name'] = test['parent_category_name'].astype('category')\n",
    "test['region'] = test['region'].astype('category')\n",
    "test['city'] = test['city'].astype('category')\n",
    "test['image_top_1'] = test['image_top_1'].fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming category_name...\n",
      "Transforming parent_category_name...\n",
      "Transforming region...\n",
      "Transforming city...\n",
      "Transforming image_top_1...\n"
     ]
    }
   ],
   "source": [
    "categorical = [\n",
    "    'category_name','parent_category_name','region','city','image_top_1'\n",
    "]\n",
    "for feature in categorical:\n",
    "    print(f'Transforming {feature}...')\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(train[feature].append(test[feature]).astype(str))\n",
    "    train[feature] = encoder.transform(train[feature].astype(str))\n",
    "    test[feature] = encoder.transform(test[feature].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_region = np.max(train.region.max())+2\n",
    "max_city= np.max(train.city.max())+2\n",
    "max_category_name = np.max(train.category_name.max())+2\n",
    "max_parent_category_name = np.max(train.parent_category_name.max())+2\n",
    "max_image_top_1 = np.max(train.image_top_1.max())+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "def data_gen(text, tabular, train_df , label):\n",
    "    batch_size = 50\n",
    "    size = len(text)\n",
    "    current_id = 0\n",
    "    while True:\n",
    "        bc = batch_size+current_id\n",
    "        if(bc < size):\n",
    "            batch_idx = range(current_id,bc)\n",
    "        else:  \n",
    "            batch_idx = range(current_id, size)\n",
    "            batch_idx = np.append(range(0,bc-size), batch_idx)\n",
    "        total_image = []\n",
    "        for i in train_df[np.array(batch_idx)]:\n",
    "            if (str(i)!='nan'):\n",
    "                img = load_img(i, target_size = (224, 224, 3))\n",
    "                x = image.img_to_array(img)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                im = x/255.\n",
    "            else:\n",
    "                im = np.zeros(shape=(224,224,3))\n",
    "            total_image.append(im)\n",
    "        total_image = np.vstack(total_image)\n",
    "        batch_idx = np.array(batch_idx)\n",
    "        yield [text[batch_idx], tabular[batch_idx], total_image], label[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "caa1e9b6-21cc-469d-9093-e55e7bcc041c",
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "6f04c12c882dc77d549b4e8b3536fde6bd750319"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  del sys.path[0]\n",
      "/home/user/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/user/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 300)     30000000    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 200, 300)     30000000    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200, 600)     0           embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 200, 600)     0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 200, 512)     1317888     spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           150         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30)           150         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)        [(None, 200, 256), ( 788480      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 60)           0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 256)          0           cu_dnnlstm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           cu_dnnlstm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 60)           0           merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 828)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 cu_dnnlstm_1[0][1]               \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 828)          3312        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 50)           41450       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 50)           50          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 50)           41450       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 50)           0           p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_2 (Merge)                 (None, 100)          0           dropout_3[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 50)           5050        merge_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50)           5050        merge_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 50)           5050        merge_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 50)           50          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 50)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 50)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 50)           0           p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_3 (Merge)                 (None, 150)          0           dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 150)          0           merge_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            151         dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 62,208,281\n",
      "Trainable params: 2,206,625\n",
      "Non-trainable params: 60,001,656\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', usecols = ['item_id', 'image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6cee72027f46bb8938c90b54094c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=508438), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "test_image_path = []\n",
    "for _ , c_row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    if(str(c_row['image'])!='nan'):\n",
    "        if(os.path.exists('data/competition_files/test/test_jpg/'+str(c_row['image'])+'.jpg')):\n",
    "            try:\n",
    "                image = Image.open('data/competition_files/test/test_jpg/' +str(c_row['image'])+'.jpg')\n",
    "                test_image_path.append('data/competition_files/test/test_jpg/'+str(c_row['image'])+'.jpg')\n",
    "            except IOError:\n",
    "                test_image_path.append('nan')\n",
    "        else:\n",
    "            test_image_path.append('nan')\n",
    "    else:\n",
    "        test_image_path.append('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', usecols = ['item_id', 'image','deal_probability'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97687ff157b34c79bdf9f13a6b93cd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1503424), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "image_path = []\n",
    "for _ , c_row in tqdm(train.iterrows(), total=train.shape[0]):\n",
    "    if(str(c_row['image'])!='nan'):\n",
    "        if(os.path.exists('data/competition_files/train/train_jpg/' + str(c_row['deal_probability'])+'/'+str(c_row['image'])+'.jpg')):\n",
    "            try:\n",
    "                image = Image.open('data/competition_files/train/train_jpg/' + str(c_row['deal_probability'])+'/'+str(c_row['image'])+'.jpg')\n",
    "                image_path.append('data/competition_files/train/train_jpg/' + str(c_row['deal_probability'])+'/'+str(c_row['image'])+'.jpg')\n",
    "            except IOError:\n",
    "                image_path.append('nan')\n",
    "        elif(os.path.exists('data/competition_files/train/val_jpg/' + str(c_row['deal_probability'])+'/'+str(c_row['image'])+'.jpg')):\n",
    "            try:\n",
    "                image = Image.open('data/competition_files/train/val_jpg/' + str(c_row['deal_probability'])+'/'+str(c_row['image'])+'.jpg')\n",
    "                image_path.append('data/competition_files/train/val_jpg/' + str(c_row['deal_probability'])+'/'+str(c_row['image'])+'.jpg')\n",
    "            except IOError:\n",
    "                image_path.append('nan')\n",
    "        else:\n",
    "            image_path.append('nan')\n",
    "    else:\n",
    "        image_path.append('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27fd75bc79d140e3aa4696a256a05992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=508438), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "test_images = []\n",
    "for tim in tqdm(test_image_path):\n",
    "    if (tim!=\"nan\"):\n",
    "        img = image.load_img(tim, target_size=(224, 224, 3))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = x/255.\n",
    "        test_images.append(x)\n",
    "    else:\n",
    "        test_images.append(np.zeros(shape=(224,224,3)))\n",
    "test_images = np.vstack(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "RS = 20180601\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=546789)\n",
    "oof_preds = np.zeros(X_train.shape[0])\n",
    "\n",
    "test_predicts_list = []\n",
    "np.random.seed(RS)\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train)):\n",
    "    batch_size = 50\n",
    "    trn_x, trn_y, features_trn, img_path_trn = X_train[trn_idx], labels['deal_probability'].values[trn_idx],features[trn_idx],image_path[trn_idx]\n",
    "    val_x, val_y, features_val, img_path_val = X_train[val_idx], labels['deal_probability'].values[val_idx], features[val_idx], image_path[val_idx]\n",
    "    trn_length = len(trn_x)\n",
    "    val_length = len(val_x)\n",
    "    model = build_model()\n",
    "    model_GPU = multi_gpu_models(model, 4)\n",
    "    check_point = ModelCheckpoint('nlp.hdf5', monitor = \"val_root_mean_squared_error\", mode = \"min\", save_best_only = True, verbose = 1)\n",
    "    early_stop = EarlyStopping(monitor=\"val_root_mean_squared_error\", mode=\"min\", patience=5)\n",
    "    rlrop = ReduceLROnPlateau(monitor='val_root_mean_squared_error',mode='auto',patience=2,verbose=1,factor=0.5,cooldown=0,min_lr=1e-6)\n",
    "    callbacks= [check_point, early_stop, rlrop]\n",
    "    model_GPU.fit_generator(generator=data_gen(trn_x, features_trn,img_path_trn, trn_y),\n",
    "                    steps_per_epoch=math.ceil(trn_length / batch_size),\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=data_gen(val_x, features_val,img_path_val, val_y),\n",
    "                    initial_epoch=0,\n",
    "                    epochs=17,\n",
    "                    use_multiprocessing=True,\n",
    "                    max_queue_size=10,\n",
    "                    workers = 20,\n",
    "                    validation_steps=math.ceil(val_length / batch_size))\n",
    "    \n",
    "    val_images = []\n",
    "    for tim in tqdm(img_path_val):\n",
    "        if (tim!=\"nan\"):\n",
    "            img = image.load_img(tim, target_size=(224, 224, 3))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = x/255.\n",
    "            val_images.append(x)\n",
    "        else:\n",
    "            val_images.append(np.zeros(shape=(224,224,3)))\n",
    "    val_images = np.vstack(val_images)\n",
    "\n",
    "    \n",
    "    oof_preds[val_idx]  = model.predict([val_x,features_val, val_images])\n",
    "    \n",
    "    pred =  model.predict([X_test, test_features, test_images])\n",
    "    test_predicts_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda, concatenate\n",
    "from keras import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def multi_gpu_models(model, gpus):\n",
    "    if isinstance(gpus, (list, tuple)):\n",
    "        num_gpus = len(gpus)\n",
    "        target_gpu_ids = gpus\n",
    "    else:\n",
    "        num_gpus = gpus\n",
    "        target_gpu_ids = range(num_gpus)\n",
    "\n",
    "    def get_slice(data, i, parts):\n",
    "        shape = tf.shape(data)\n",
    "        batch_size = shape[:1]\n",
    "        input_shape = shape[1:]\n",
    "        step = batch_size // parts\n",
    "        if i == num_gpus - 1:\n",
    "            size = batch_size - step * i\n",
    "        else:\n",
    "            size = step\n",
    "        size = tf.concat([size, input_shape], axis=0)\n",
    "        stride = tf.concat([step, input_shape * 0], axis=0)\n",
    "        start = stride * i\n",
    "        return tf.slice(data, start, size)\n",
    "\n",
    "    all_outputs = []\n",
    "    for i in range(len(model.outputs)):\n",
    "        all_outputs.append([])\n",
    "\n",
    "    # Place a copy of the model on each GPU,\n",
    "    # each getting a slice of the inputs.\n",
    "    for i, gpu_id in enumerate(target_gpu_ids):\n",
    "        with tf.device('/gpu:%d' % gpu_id):\n",
    "            with tf.name_scope('replica_%d' % gpu_id):\n",
    "                inputs = []\n",
    "                # Retrieve a slice of the input.\n",
    "                for x in model.inputs:\n",
    "                    input_shape = tuple(x.get_shape().as_list())[1:]\n",
    "                    slice_i = Lambda(get_slice,\n",
    "                                     output_shape=input_shape,\n",
    "                                     arguments={'i': i,\n",
    "                                                'parts': num_gpus})(x)\n",
    "                    inputs.append(slice_i)\n",
    "\n",
    "                # Apply model on slice\n",
    "                # (creating a model replica on the target device).\n",
    "                outputs = model(inputs)\n",
    "                if not isinstance(outputs, list):\n",
    "                    outputs = [outputs]\n",
    "\n",
    "                # Save the outputs for merging back together later.\n",
    "                for o in range(len(outputs)):\n",
    "                    all_outputs[o].append(outputs[o])\n",
    "\n",
    "          # Merge outputs on CPU.\n",
    "    with tf.device('/cpu:0'):\n",
    "        merged = []\n",
    "        for name, outputs in zip(model.output_names, all_outputs):\n",
    "            merged.append(concatenate(outputs,\n",
    "                                       axis=0, name=name))\n",
    "        return Model(model.inputs, merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate, Flatten, Bidirectional, CuDNNLSTM, GlobalMaxPooling1D, concatenate,BatchNormalization\n",
    "from keras.layers import PReLU, merge,GlobalAveragePooling2D, Conv2D, Conv1D\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    features_input = Input(shape=(features.shape[1],))\n",
    "    feat_x = Dense(30, activation='sigmoid')(features_input)\n",
    "    feat_x2 = Dense(30)(features_input)\n",
    "    feat_x2 = PReLU()(feat_x2)\n",
    "    x1 = merge([feat_x, feat_x2], mode='concat')\n",
    "    x1 = Dropout(0.2)(x1)\n",
    "    \n",
    "    region = Input(shape=[1])\n",
    "    city = Input(shape=[1])\n",
    "    category_name = Input(shape=[1])\n",
    "    parent_category_name = Input(shape=[1])\n",
    "    image_top_1 = Input(shape=[1])\n",
    "    \n",
    "    emb_region = Embedding(max_region, 10)(region)\n",
    "    emb_city = Embedding(max_city, 10)(city)\n",
    "    emb_category_name = Embedding(max_category_name, 10)(category_name)\n",
    "    emb_parent_category_name = Embedding(max_parent_category_name, 10)(parent_category_name)\n",
    "    emb_image_top_1 =  Embedding(max_image_top_1, 10)(image_top_1)\n",
    "    region_f = Flatten() (emb_region)\n",
    "    city_f = Flatten() (emb_city)\n",
    "    cat_name_f = Flatten() (emb_category_name)\n",
    "    par_cat_name_f = Flatten() (emb_parent_category_name)\n",
    "    ito_f = Flatten() (emb_image_top_1)\n",
    "    categorical_feat = Concatenate()([region_f, city_f, cat_name_f, par_cat_name_f,ito_f])\n",
    "    cat_x = Dense(30, activation='sigmoid')(categorical_feat)\n",
    "    cat_x = Dropout(0.2)(cat_x)\n",
    "    cat_x2 = Dense(30)(categorical_feat)\n",
    "    cat_x2 = PReLU()(cat_x2)\n",
    "    cat_x2 = Dropout(0.2)(cat_x2)\n",
    "    cat_m = merge([cat_x, cat_x2], mode='concat')\n",
    "    cat_m = Dropout(0.2)(cat_m)\n",
    "    \n",
    "    \n",
    "    inp = Input(shape = (maxlen, ))\n",
    "    inp_eng = Input(shape = (maxlen, ))\n",
    "    emb = Embedding(nb_words, embed_size, weights = [embedding_matrix],\n",
    "                    input_length = maxlen, trainable = False)(inp)\n",
    "    \n",
    "    embedding = Embedding(nb_words, embed_size, weights = [embedding_matrix_image],\n",
    "                    input_length = maxlen, trainable = False)(inp)\n",
    "    \n",
    "    embedding_eng = Embedding(nb_words, embed_size, weights = [embedding_matrix_image_two],\n",
    "                    input_length = maxlen, trainable = False)(inp_eng)\n",
    "    \n",
    "    #eng = Bidirectional(CuDNNGRU(256,return_sequences = True))(embedding_eng)\n",
    "    #x_eng, x_h_eng, x_c_eng = CuDNNLSTM(256,return_sequences=True, return_state=True)(eng)\n",
    "    #avg_pool_eng = GlobalAveragePooling1D()(x_eng)\n",
    "    #max_pool_eng = GlobalMaxPooling1D()(x_eng)\n",
    "    \n",
    "    final_emb = Concatenate()([emb, embedding, embedding_eng])\n",
    "    \n",
    "    main = SpatialDropout1D(0.2)(final_emb)\n",
    "    #main = Conv1D(256, kernel_size=3, padding='valid')(main)\n",
    "    \n",
    "    main = Bidirectional(CuDNNGRU(256,return_sequences = True))(main)\n",
    "    \n",
    "    main = Bidirectional(CuDNNGRU(256,return_sequences = True))(main)\n",
    "    \n",
    "    x, x_h, x_c = CuDNNLSTM(256,return_sequences=True, return_state=True)(main)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    x = concatenate([avg_pool, max_pool, x_h, x1, cat_m]) \n",
    "    x = BatchNormalization()(x)\n",
    "    x3 = Dense(100, activation='sigmoid')(x)\n",
    "    x3 = Dropout(0.2)(x3)\n",
    "    x2  = Dense(100)(x)\n",
    "    x2 = PReLU()(x2)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "    x = merge([x2,x3], mode='concat')\n",
    "    x2 = Dense(30, activation='sigmoid')(x)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "    x3 = Dense(30, activation = 'linear')(x)\n",
    "    x3 = Dropout(0.2)(x3)\n",
    "    x4 = Dense(30)(x)\n",
    "    x4 = PReLU()(x4)\n",
    "    x4 = Dropout(0.2)(x4)\n",
    "    x = merge([x2,x3,x4], mode='concat')\n",
    "    main = Dropout(0.2)(x)\n",
    "    out = Dense(1, activation = \"sigmoid\")(main)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs = [inp, inp_eng,features_input, region, city, category_name,\n",
    "                            parent_category_name,image_top_1], outputs = out)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr=0.001), loss = 'mean_squared_error',\n",
    "                  metrics =[root_mean_squared_error])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n",
      "/home/user/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:76: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:84: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1353081 samples, validate on 150343 samples\n",
      "Epoch 1/1000\n",
      " 336000/1353081 [======>.......................] - ETA: 3:54 - loss: 0.2964 - root_mean_squared_error: 0.2964"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "RS = 20180601\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=546789)\n",
    "oof_preds = np.zeros(X_train.shape[0])\n",
    "catt_feat = ['region','city','category_name','parent_category_name','image_top_1']\n",
    "test_predicts_list = []\n",
    "np.random.seed(RS)\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train)):\n",
    "    trn_x, trn_y, features_trn, categ_trn = X_train[trn_idx], labels['deal_probability'].values[trn_idx], features[trn_idx], train[catt_feat].loc[trn_idx].values\n",
    "    val_x, val_y, features_val, categ_val = X_train[val_idx], labels['deal_probability'].values[val_idx], features[val_idx], train[catt_feat].loc[val_idx].values\n",
    "    \n",
    "    model = build_model()\n",
    "    model_gpu = multi_gpu_models(model,4)\n",
    "    #model_gpu.compile(optimizer = Adam(lr=0.005), loss = 'mean_squared_error',\n",
    "    model_gpu.compile(optimizer = Adam(lr=0.005), loss = root_mean_squared_error,\n",
    "                  metrics =[root_mean_squared_error])\n",
    "    \n",
    "    check_point = ModelCheckpoint('nlp.hdf5', monitor = \"val_root_mean_squared_error\", mode = \"min\",\n",
    "                                  save_best_only = True, verbose = 1)\n",
    "    early_stop = EarlyStopping(monitor=\"val_root_mean_squared_error\", mode=\"min\", patience=5)\n",
    "    rlrop = ReduceLROnPlateau(monitor='val_root_mean_squared_error',mode='auto',patience=1,verbose=1,\n",
    "                              factor=0.5,cooldown=0,min_lr=1e-6)\n",
    "    history = model_gpu.fit([trn_x,trn_eng_x, features_trn, categ_trn[:,0],categ_trn[:,1],categ_trn[:,2],categ_trn[:,3],\n",
    "                             categ_trn[:,4]], trn_y, batch_size = 2000, epochs = 1000,\n",
    "                            validation_data = ([val_x,val_eng_x, features_val,categ_val[:,0],categ_val[:,1],\n",
    "                                                categ_val[:,2],categ_val[:,3],categ_val[:,4]], val_y),verbose = 1,\n",
    "                            callbacks = [check_point, early_stop, rlrop])\n",
    "    oof_preds[val_idx]  = model_gpu.predict([val_x,features_val,categ_val[:,0],categ_val[:,1],\n",
    "                                                categ_val[:,2],categ_val[:,3],categ_val[:,4]]).reshape(-1)\n",
    "    pred =  model_gpu.predict([X_test,  test_features, test[catt_feat[0]],test[catt_feat[1]],test[catt_feat[2]],\n",
    "                          test[catt_feat[3]],test[catt_feat[4]]])\n",
    "    test_predicts_list.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with English text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n",
      "/home/user/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:76: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:84: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1353081 samples, validate on 150343 samples\n",
      "Epoch 1/1000\n",
      "1353081/1353081 [==============================] - 437s 323us/step - loss: 0.2954 - root_mean_squared_error: 0.2954 - val_loss: 0.2958 - val_root_mean_squared_error: 0.2958\n",
      "\n",
      "Epoch 00001: val_root_mean_squared_error improved from inf to 0.29576, saving model to nlp.hdf5\n",
      "Epoch 2/1000\n",
      "1353081/1353081 [==============================] - 430s 317us/step - loss: 0.2947 - root_mean_squared_error: 0.2947 - val_loss: 0.2958 - val_root_mean_squared_error: 0.2958\n",
      "\n",
      "Epoch 00002: val_root_mean_squared_error did not improve from 0.29576\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.003999999910593033.\n",
      "Epoch 3/1000\n",
      " 574000/1353081 [===========>..................] - ETA: 3:55 - loss: 0.2950 - root_mean_squared_error: 0.2950"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-fe309b9b5989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                             validation_data = ([val_x,val_eng_x, features_val,categ_val[:,0],categ_val[:,1],\n\u001b[1;32m     27\u001b[0m                                                 categ_val[:,2],categ_val[:,3],categ_val[:,4]], val_y),verbose = 1,\n\u001b[0;32m---> 28\u001b[0;31m                             callbacks = [check_point, early_stop, rlrop])\n\u001b[0m\u001b[1;32m     29\u001b[0m     oof_preds[val_idx]  = model_gpu.predict([val_x,val_eng_x,features_val,categ_val[:,0],categ_val[:,1],\n\u001b[1;32m     30\u001b[0m                                                 categ_val[:,2],categ_val[:,3],categ_val[:,4]]).reshape(-1)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "RS = 20180601\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=546789)\n",
    "oof_preds = np.zeros(X_train.shape[0])\n",
    "catt_feat = ['region','city','category_name','parent_category_name','image_top_1']\n",
    "test_predicts_list = []\n",
    "np.random.seed(RS)\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train)):\n",
    "    trn_x, trn_eng_x, trn_y, features_trn, categ_trn = X_train[trn_idx], X_eng_train[trn_idx], labels['deal_probability'].values[trn_idx], features[trn_idx], train[catt_feat].loc[trn_idx].values\n",
    "    val_x, val_eng_x, val_y, features_val, categ_val = X_train[val_idx], X_eng_train[val_idx], labels['deal_probability'].values[val_idx], features[val_idx], train[catt_feat].loc[val_idx].values\n",
    "    \n",
    "    model = build_model()\n",
    "    model_gpu = multi_gpu_models(model,4)\n",
    "    #model_gpu.compile(optimizer = Adam(lr=0.005), loss = 'mean_squared_error',\n",
    "    model_gpu.compile(optimizer = Adam(lr=0.01), loss = root_mean_squared_error,\n",
    "                  metrics =[root_mean_squared_error])\n",
    "    \n",
    "    check_point = ModelCheckpoint('nlp.hdf5', monitor = \"val_root_mean_squared_error\", mode = \"min\",\n",
    "                                  save_best_only = True, verbose = 1)\n",
    "    early_stop = EarlyStopping(monitor=\"val_root_mean_squared_error\", mode=\"min\", patience=5)\n",
    "    rlrop = ReduceLROnPlateau(monitor='val_root_mean_squared_error',mode='auto',patience=1,verbose=1,\n",
    "                              factor=0.5,cooldown=0,min_lr=1e-6)\n",
    "    history = model_gpu.fit([trn_x,trn_eng_x, features_trn, categ_trn[:,0],categ_trn[:,1],categ_trn[:,2],categ_trn[:,3],\n",
    "                             categ_trn[:,4]], trn_y, batch_size = 2000, epochs = 1000,\n",
    "                            validation_data = ([val_x,val_eng_x, features_val,categ_val[:,0],categ_val[:,1],\n",
    "                                                categ_val[:,2],categ_val[:,3],categ_val[:,4]], val_y),verbose = 1,\n",
    "                            callbacks = [check_point, early_stop, rlrop])\n",
    "    oof_preds[val_idx]  = model_gpu.predict([val_x,val_eng_x,features_val,categ_val[:,0],categ_val[:,1],\n",
    "                                                categ_val[:,2],categ_val[:,3],categ_val[:,4]]).reshape(-1)\n",
    "    pred =  model_gpu.predict([X_test, X_eng_test,  test_features, test[catt_feat[0]],test[catt_feat[1]],test[catt_feat[2]],\n",
    "                          test[catt_feat[3]],test[catt_feat[4]]])\n",
    "    test_predicts_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = np.zeros(shape=(1000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_generator(generator=my_generator(train_generator),\n",
    "                    steps_per_epoch=math.ceil(1104367 / batch_size),\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=my_generator(validation_generator),\n",
    "                    initial_epoch=16,\n",
    "                    epochs=17,\n",
    "                    use_multiprocessing=True,\n",
    "                    max_queue_size=10,\n",
    "                    workers = 20,\n",
    "                    validation_steps=math.ceil(114799 / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicts = np.ones(test_predicts_list[0].shape)\n",
    "for fold_predict in test_predicts_list:\n",
    "    test_predicts *= fold_predict\n",
    "\n",
    "test_predicts **= (1. / len(test_predicts_list))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predictions/four/rnn_mlp_oof_preds.npy',oof_preds)\n",
    "np.save('predictions/four/rnn_mlp_test_predicts.npy',test_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv', index_col = 0)\n",
    "submission = sample_submission.copy()\n",
    "submission['deal_probability'] = test_predicts\n",
    "submission.to_csv('mark_rnn_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py:816: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = getattr(x, name)(y)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid type comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-5e7012e9d25c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'deal_probability'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid type comparison\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid type comparison"
     ]
    }
   ],
   "source": [
    "submission[submission['deal_probability']=='']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "59e0f0861d480e994e250509f3443ed57b7474c9"
   },
   "source": [
    "Lets define the model and illustrate the architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fcb3ffa301fac8fe3faf380aa48c4fd09647bb14"
   },
   "source": [
    "Lets train our model for four epochs and save the best epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 4\n",
    "file_path = \"model.hdf5\"\n",
    "\n",
    "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", mode = \"min\", save_best_only = True, verbose = 1)\n",
    "history = model.fit(X_train, y_train, batch_size = 256, epochs = EPOCHS, validation_data = (X_valid, y_valid),\n",
    "                verbose = 1, callbacks = [check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "04a70f03-f676-4081-b7a6-ef0dae1c048b",
    "_uuid": "d79d956c4f47381479a397069fe06f0f5a7c49b0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(TEST_CSV, index_col = 0)\n",
    "test = test[['description']].copy()\n",
    "\n",
    "test['description'] = test['description'].astype(str)\n",
    "X_test = test['description'].values\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "print('padding')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "prediction = model.predict(X_test,batch_size = 128, verbose = 1)\n",
    "\n",
    "sample_submission = pd.read_csv('../input/avito-demand-prediction/sample_submission.csv', index_col = 0)\n",
    "submission = sample_submission.copy()\n",
    "submission['deal_probability'] = prediction\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "382825ef-434e-4f9e-8a63-4af894ced750",
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "2d91fb63f6b08a3b488bc8517088d4a8c923519c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(file_path)\n",
    "prediction = model.predict(X_valid)\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_valid, prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cb596e1c0df5ef051c7f8ac3700fd5aa08ff793c"
   },
   "source": [
    "Thats some improvement compared to using  [the pre-trained embedding model](https://www.kaggle.com/christofhenkel/fasttext-starter-description-only) which scored 0.2370. Additionally since the embeddings here are trained also on param_1, param_2, param_3 and title which have much more out of vocabulary words when using Fasttext. Hence self-trained embeddings are clearly performing better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e743df07753b5b8094739842736f26288fc6381"
   },
   "source": [
    "Ok, now we are ready to do a submission and compare the LB score with [the pre-trained embedding model](https://www.kaggle.com/christofhenkel/fasttext-starter-description-only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dfa1edc4a6531d84ba560d3cc1838e15b53177c9",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
